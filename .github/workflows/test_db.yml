name: DB script using matrix 

on: push

env:
  AWS_REGION: 'us-east-1'
  RDS_HOST: 'pocdb1.ciwtq0frolty.us-east-1.rds.amazonaws.com'
  RDS_PORT: '5432'
  RDS_USERNAME: 'postgres'
  PGPASSWORD: ${{ secrets.RDS_PASSWORDS }}
  AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
  AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  MIGRATION_FOLDER: 'src/migrations/ddl'

jobs:
  migration-required-or-not:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        include:
          - folder: 'src/migrations/ddl'
            migration_column: 'ddl' 
        #   - folder: 'src/migrations/triggers'
        #     migration_column: 'triggers' 
        #   - folder: 'src/migrations/stored_procedures'
        #     migration_column: 'stored_procedure'             
    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Install dependencies
        run: npm install

      - name: Get migration history version
        id: get_migration_history
        run: |          
          query_output=$(psql -h $RDS_HOST -p $RDS_PORT -U $RDS_USERNAME -d poc -t -c "select ${{ matrix.migration_column }} from \"_MigrationsHistory\" order by migration_id desc limit 1" 2>&1)
          echo "Output- $query_output"

          echo "${{ matrix.migration_column }}=$query_output" >> $GITHUB_OUTPUT
        #   echo "::set-output name=migration_history_version::$query_output"
        #   echo "MigrationHistoryVersion=$query_output" >> "$GITHUB_OUTPUT"
    outputs:
            ddl: ${{ steps.get_migration_history.outputs.ddl }}
            # triggers: ${{ steps.get_migration_history.outputs.triggers }}
            # stored_procedure: ${{ steps.get_migration_history.outputs.stored_procedure }}
  get-files-from-folder:
    runs-on: ubuntu-latest
    needs: migration-required-or-not 
    strategy:
        matrix:
          include:
            - folder: 'src/migrations/ddl'
              db_version: ${{ needs.migration-required-or-not.outputs.ddl }} 
              migration_column: 'ddl' 
            # - folder: 'src/migrations/triggers'
            #   db_version: ${{ needs.migration-required-or-not.outputs.triggers }}
            #   migration_column: 'triggers' 
            # - folder: 'src/migrations/stored_procedures'
            #   db_version: ${{ needs.migration-required-or-not.outputs.stored_procedure }} 
            #   migration_column: 'stored_procedure'    
    outputs:
        ddl_dbUpdateRequired: ${{steps.filename_read.outputs.ddl_dbUpdateRequired}}
        ddl_scriptFileHash: ${{steps.filename_read.outputs.ddl_scriptFileHash}}
        # triggers_dbUpdateRequired: ${{steps.filename_read.outputs.triggers_dbUpdateRequired}}
        # triggers_scriptFileHash: ${{steps.filename_read.outputs.triggers_scriptFileHash}}
        # stored_procedure_dbUpdateRequired: ${{steps.filename_read.outputs.stored_procedure_dbUpdateRequired}}
        # stored_procedure_scriptFileHash: ${{steps.filename_read.outputs.stored_procedure_scriptFileHash}}     
    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Install dependencies
        run: npm install

      - name: Print results of above step
        run: |
         echo 'Result of version- ${{ matrix.db_version }}'
         
      - name: Get all the scripts from configured folder
        id: filename_read
        run: |
           migrationHistoryVersion="${{  matrix.db_version }}"
           MIGRATION_FOLDER=${{ matrix.folder }}

           echo "migrationHistoryVersion: $migrationHistoryVersion"

           declare -A scriptToExecute
           declare -A scriptFileHash
           db_updateRequired=false

            i=0
            shopt -s dotglob

            for file in $(ls "$MIGRATION_FOLDER"); do
                echo "File name:$file"
                scriptFiles=(${scriptFiles[@]} "$file")
                IFS='_' read -ra splitName <<< "$file"
                scriptFileHash["${splitName[0]}"]="${file}"          
            done

            # Get script file name with succeeding version number
            for key in "${!scriptFileHash[@]}"; do                    
                if [ "$key" -gt "$migrationHistoryVersion" ];then 
                    scriptToExecute[$i]="${scriptFileHash[$key]}"
                    i=$((i + 1))
                fi
            done          
            
            if [ ${#scriptToExecute[@]} != 0 ]; then
                db_updateRequired=true
                echo -e "\033[0;32mThere is atleast one script file with higher version number than Migration History version.Following files will be executed on Prod db.\033[0m"            
                for scriptName in "${scriptToExecute[@]}"; do
                echo "${scriptName}"             
                done             
            fi

            # echo "Can run further: ${db_updateRequired}"
            # Convert scriptFileHash to JSON string         
            hashmap_json="{"
            first=true
            for key in "${!scriptFileHash[@]}"; do
                if [ "$first" = true ]; then
                first=false
                else
                hashmap_json+=","
                fi
                hashmap_json+="\"$key\":\"${scriptFileHash[$key]}\""
            done
            hashmap_json+=$(printf '%s' '}')
            
            echo "Debug:"
            echo "$hashmap_json"
            echo "-----------------------------------"
 
           # Set the output
           echo "::set-output name=${{ matrix.migration_column }}_dbUpdateRequired::$db_updateRequired"
           echo "::set-output name=${{ matrix.migration_column }}_scriptFileHash::$hashmap_json"

  script-validation-on-shadow-db:
    needs: 
        - get-files-from-folder
        - migration-required-or-not
    runs-on: ubuntu-latest    
    # Service containers to run with `container-job`
    services:
        # Label used to access the service container
       postgres:
        # Docker Hub image
        image: postgres:latest
        # Provide the password for postgres
        env:
            POSTGRES_PASSWORD: postgres
            POSTGRES_USER: postgres
            POSTGRES_DB: shadowDb
        # Set health checks to wait until postgres has started
        options: >-
            --health-cmd pg_isready
            --health-interval 10s
            --health-timeout 5s
            --health-retries 5
        ports:
            # Maps tcp port 5432 on service container to the host
          - 5432:5432
        
    if: ${{needs.get-files-from-folder.outputs.ddl_dbUpdateRequired=='true'}}
    steps: 
       - name: Check out repository code
         uses: actions/checkout@v2

        # Performs a clean installation of all dependencies in the `package.json` file      
       - name: Install dependencies
         run: npm ci

       - name: Set Environment Variables from File
         uses: ./.github/actions/setup-environment
         with:
            var_file_path: ./.github/variables/db_automation.env


    #    - name: Get Shadow db version
    #      id: shadow-db
    #      run: |
    #         export PGPASSWORD=postgres
    #         shadow_db_version_temp=$(psql -h 'localhost' -p '5432' -U postgres  -d shadowDb  -t -c "show server_version;" 2>&1)            
    #         shadow_db_version=$(echo $shadow_db_version_temp | awk '{print $1}' | cut -d '.' -f1,2)
    #         echo "version=$shadow_db_version" >> "$GITHUB_OUTPUT"
    #         echo "Shadow db version: $shadow_db_version"

    #    - name: Get Production db version
    #      id: prod-db
    #      run: |
    #         export PGPASSWORD=${{ secrets.RDS_PASSWORDS }}
    #         prod_db_version_temp=$(psql -h $RDS_HOST -d $RDS_DB -p $RDS_PORT -U $RDS_USERNAME  -t -c "show server_version;" 2>&1)
    #         prod_db_version=$(echo $prod_db_version_temp | awk '{print $1}' | cut -d '.' -f1,2)
    #         echo "Production db version-${prod_db_version}"
    #         echo "version=$prod_db_version" >> "$GITHUB_OUTPUT"

    #    - name: Compare Shadow vs Prod db scripts
    #      run: |
    #         if [[ "${{ steps.shadow-db.outputs.version }}" != "${{ steps.prod-db.outputs.version }}" ]]; then 
    #             echo -e "\033[0;33mWarning: Prod db version is not same as shadow db version. Please take corrective action.\033[0m"                                
    #         fi
        
       - name: Sort all the script filenames & execute them in order        
         id: scripts_required_to_run
         run: |
            # migrationFolder="${{ needs.get-files-from-folder.outputs}}"
            migrationHistoryVersion="${{ needs.migration-required-or-not.outputs.ddl }}"
            echo "migrationHistoryVersion: $migrationHistoryVersion"
            declare -A hashmap
            declare -A scriptToExecute
            i=0
            j=0
            echo "${{needs.get-files-from-folder.outputs.ddl_scriptFileHash}}"
            # Access the hashmap JSON string
            hashmap_json=${{ needs.get-files-from-folder.outputs.ddl_scriptFileHash }}
            
            # Deserialize JSON to an associative array
            IFS=':,{}' read -ra tempArray <<< "$hashmap_json"           
            
            for key in ${tempArray[@]}; do
                i=$((i + 1))      
                if [ $(($i%2)) == 0 ]; then                                         
                    hashmap["${tempArray[$((i-1))]}"]="${key}"                       
                else                 
                    tempkey="${key}"                 
                fi
            done

            #output the hashed set from the step.
            sorted_keys=($(for key in "${!hashmap[@]}"; do echo "$key"; done | sort))

            can_run_on_prod=true
            echo "Running scripts over Shadow db...."
            for key in "${sorted_keys[@]}"; do              
                value=${hashmap[$key]}
                file="${MIGRATION_FOLDER}/${value}"
                
                echo "Executing script file: ${file}"
                export PGPASSWORD=postgres
                query_output=$(psql -h 'localhost' -p '5432' -U postgres  -d shadowDb  -f "$file" 2>&1)
                # Convert output to lowercase
                converted_output="${query_output,,}"
                echo "Query output: ${converted_output}"
                echo "-----------------------------------------------------------------------"

                if echo "$converted_output" | grep -q "error"; then
                    can_run_on_prod=false
                    echo -e "\033[0;31mError in script execution. Can not run on Prod.\033[0m"
                    break;
                fi
            done
            
            echo "Execution completed on Shadow db."
            echo "can_run_on_prod=$can_run_on_prod" >>"$GITHUB_OUTPUT"

            # Create the array of filenames to execute on Prod
            if [ "$can_run_on_prod" = true ]; then
                 for key in "${!hashmap[@]}"; do             
                    if(($key>$migrationHistoryVersion)); then 
                        scriptToExecute[$j]="${hashmap[$key]}"
                        j=$((j + 1))
                    fi
                 done
            fi

            #convert into a json to output the same.
            scripts_for_prod=$(IFS=,; echo "${scriptToExecute[*]}")
            echo "scripts_for_prod_json=$scripts_for_prod" >> $GITHUB_OUTPUT


            # if [ "$can_run_on_prod" = true ]; then
            #     echo "Running scripts on Prod db..."
            #     # run incremental scripts on Prod db.
            #     for key in "${!hashmap[@]}"; do             
            #     if(($key>$migrationHistoryVersion)); then 
                    
            #         file="${MIGRATION_FOLDER}/${hashmap[$key]}"
            #         export PGPASSWORD=${{ secrets.RDS_PASSWORDS }}
            #         echo "Executing file- ${file}"
            #         psql -h $RDS_HOST -d $RDS_DB -p $RDS_PORT -U $RDS_USERNAME -f "$file"           
            #     fi
            #     done
            #     echo -e "\033[0;32mExecution completed on Production db.\033[0m"
            # fi
            echo "shadow_db_run_successful=$can_run_on_prod" >> "$GITHUB_OUTPUT"
       - name: Run the scripts on Production
         if: ${{steps.scripts_required_to_run.outputs.can_run_on_prod=='true'}}
         run: |
            prod_scripts_to_run="${{ steps.scripts_required_to_run.outputs.scripts_for_prod_json }}"
            echo "Production script names is - $prod_scripts_to_run"
            echo "Running scripts on Prod db..."
            IFS=',' read -ra scripts <<< "${prod_scripts_to_run}"
            for script_name in "${scripts[@]}"; do
                echo "String: $script_name"
                file="${MIGRATION_FOLDER}/${script_name}"
                export PGPASSWORD=${{ secrets.RDS_PASSWORDS }}
                echo "Executing file- ${file}"
                psql -h $RDS_HOST -d $RDS_DB -p $RDS_PORT -U $RDS_USERNAME -f "$file"                                           
            done
            echo -e "\033[0;32mExecution completed on Production db.\033[0m"